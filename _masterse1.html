<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"  
  "http://www.w3.org/TR/html4/loose.dtd">  
<html > 
<head><title>Introduction</title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"> 
<meta name="generator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)"> 
<meta name="originator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)"> 
<!-- 2,html --> 
<meta name="src" content="_master.tex"> 
<meta name="date" content="2014-08-30 18:05:00"> 
<link rel="stylesheet" type="text/css" href="_master.css"> 
</head><body 
>
   <!--l. 2--><div class="crosslinks"><p class="noindent">[<a 
href="_masterse2.html" >next</a>] [<a 
href="#tail_masterse1.html">tail</a>] [<a 
href="_master.html#_masterse1.html" >up</a>] </p></div>
   <h3 class="sectionHead"><span class="titlemark">1   </span> <a 
 id="x2-10001"></a>Introduction</h3>
<!--l. 11--><p class="noindent" >Accurate motion perception is essential for visually guided movement; complex behaviors such as
chasing prey, escaping predators, avoiding obstacles, or catching a thrown ball require that an
organism be able to rapidly determine the position and velocity of a moving object, and to
anticipate its trajectory through space. Psychological research on motion perception has
established that motion can be processed by separate mechanisms, an idea that dates back to
Wertheimer&#8217;s phenomenological distinction between the &#8220;phi&#8221; sensation elicited by faster motion
and the &#8220;beta&#8221; sensation elicited by slower motion (<a 
href="_masterli1.html#XWertheimer:1912aa">Wertheimer</a>&#x00A0;<a 
href="_masterli1.html#XWertheimer:1912aa">1912</a>, <a 
href="_masterli1.html#XWertheimer:2012aa">2012</a>; <a 
href="_masterli1.html#XSteinman:2000ap">Steinman
et&#x00A0;al.</a>,&#x00A0;<a 
href="_masterli1.html#XSteinman:2000ap">2000</a>). The goal of this thesis is to examine how separate mechanisms contribute to a
unified perception of motion.
                                                                                         
                                                                                         
<!--l. 24--><p class="indent" >   It is generally believed that there are multiple classes of motion mechanisms. One of these, the
first-order motion mechanism, seems to respond to local spatiotemporal correlations in luminance
contrast, at relatively short timescales and in small regions of space. It is generally agreed that
the first-order motion mechanism originates with the direction selective response of
cells in cortical area V1. Classic models of first-order motion detection use linear filters
tuned to certain combinations of spatial and temporal frequencies, with the outputs of
several such filters being combined nonlinearly (<a 
href="_masterli1.html#XAdelson:1985ea">Adelson and Bergen</a>,&#x00A0;<a 
href="_masterli1.html#XAdelson:1985ea">1985</a>;&#x00A0;<a 
href="_masterli1.html#XWatson:1985aa">Watson and
Ahumada</a>,&#x00A0;<a 
href="_masterli1.html#XWatson:1985aa">1985</a>). With some embellishments, the responses observed from cells in area V1 are
largely compatible with this model (<a 
href="_masterli1.html#XMovshon:1978qq">Movshon et&#x00A0;al.</a>,&#x00A0;<a 
href="_masterli1.html#XMovshon:1978qq">1978</a>;&#x00A0;<a 
href="_masterli1.html#XRust:2005vu">Rust et&#x00A0;al.</a>,&#x00A0;<a 
href="_masterli1.html#XRust:2005vu">2005</a>;&#x00A0;<a 
href="_masterli1.html#XTouryan:2005aa">Touryan
et&#x00A0;al.</a>,&#x00A0;<a 
href="_masterli1.html#XTouryan:2005aa">2005</a>;&#x00A0;<a 
href="_masterli1.html#XChen:2007aa">Chen et&#x00A0;al.</a>,&#x00A0;<a 
href="_masterli1.html#XChen:2007aa">2007</a>), and models of higher order processing can be built atop this
basis (<a 
href="_masterli1.html#XGraham:2011aa">Graham</a>,&#x00A0;<a 
href="_masterli1.html#XGraham:2011aa">2011</a>). Moreover, the size and bandwidth of motion sensing channels
inferred from psychophysical measurements are similar to those observed of V1 neurons
(<a 
href="_masterli1.html#XAnderson:1987oq">Anderson and Burr</a>,&#x00A0;<a 
href="_masterli1.html#XAnderson:1987oq">1987</a>,&#x00A0;<a 
href="_masterli1.html#XAnderson:1989nx">1989</a>;&#x00A0;<a 
href="_masterli1.html#XBanks:1991kl">Banks et&#x00A0;al.</a>,&#x00A0;<a 
href="_masterli1.html#XBanks:1991kl">1991</a>;&#x00A0;<a 
href="_masterli1.html#XAnderson:1991tg">Anderson et&#x00A0;al.</a>,&#x00A0;<a 
href="_masterli1.html#XAnderson:1991tg">1991</a>;&#x00A0;<a 
href="_masterli1.html#XWatson:1995fh">Watson and
Turano</a>,&#x00A0;<a 
href="_masterli1.html#XWatson:1995fh">1995</a>).
<!--l. 41--><p class="indent" >   However, these first-order mechanisms cannot by themselves fully explain human motion
perception. For example, perceiving visual motion does not necessarily require moving features to
differ in mean luminance from the background, and does not require motion energy in
the Fourier domain. Many forms of higher-order motion stimuli have been constructed
that would not be consistently detectable to first-order mechanisms, but these stimuli
still elicit strong sensations of movement (<a 
href="_masterli1.html#XDerrington:1985aa">Derrington and Badcock</a>,&#x00A0;<a 
href="_masterli1.html#XDerrington:1985aa">1985</a>;&#x00A0;<a 
href="_masterli1.html#XChubb:1988kx">Chubb and
Sperling</a>,&#x00A0;<a 
href="_masterli1.html#XChubb:1988kx">1988</a>;&#x00A0;<a 
href="_masterli1.html#XZanker:1990aa">Zanker</a>,&#x00A0;<a 
href="_masterli1.html#XZanker:1990aa">1990</a>). These stimuli have been used to provide evidence for and
characterize motion sensing systems separate from the first-order mechanisms. They have been
constructed variously by modulations in contrast, texture, or other stimulus features, but
generally involve the change in position, over time, of some feature in the image (<a 
href="_masterli1.html#XLu:1995la">Lu and
Sperling</a>,&#x00A0;<a 
href="_masterli1.html#XLu:1995la">1995</a>).
<!--l. 55--><p class="indent" >   One possible reason for having multiple motion systems is that first-order motion signals are
                                                                                         
                                                                                         
not always a reliable indication of the veridical motion of an object. In a complicated visual world,
motion can come from many sources, and accurate perception of the movement of objects requires
disambiguating motion signals attributable to the object from irrelevant motions in the
background or of other objects. Consider the task of trying to track the movement of a zebra
among a background of waving grass. One challenge this task presents is that a motion energy
sensor with a limited receptive field size will report the component of the zebra&#8217;s motion
orthogonal to its stripes, rather than the veridical motion of the zebra, an instance of the so-called
&#8220;aperture problem&#8221; (<a 
href="_masterli1.html#XIlildreth:1982aa">Ilildreth and Ullman</a>,&#x00A0;<a 
href="_masterli1.html#XIlildreth:1982aa">1982</a>;&#x00A0;<a 
href="_masterli1.html#XAdelson:1982jr">Adelson and Movshon</a>,&#x00A0;<a 
href="_masterli1.html#XAdelson:1982jr">1982</a>). Combining
the component motion signals from V1 cells sensing different orientations might allow
disambiguation of the true velocity. This extraction of pattern motion from component motion
appears to be one of the roles of visual area MT (<a 
href="_masterli1.html#XMovshon:1985hb">Movshon et&#x00A0;al.</a>,&#x00A0;<a 
href="_masterli1.html#XMovshon:1985hb">1985</a>;&#x00A0;<a 
href="_masterli1.html#XSimoncelli:1998hb">Simoncelli and
Heeger</a>,&#x00A0;<a 
href="_masterli1.html#XSimoncelli:1998hb">1998</a>;&#x00A0;<a 
href="_masterli1.html#XRust:2006el">Rust et&#x00A0;al.</a>,&#x00A0;<a 
href="_masterli1.html#XRust:2006el">2006</a>). However, this computation of pattern motion cannot
completely explain motion perception either, as combining different motion signals allows the
object&#8217;s motion to be mixed with irrelevant background motion. If motion information is
pooled over larger areas, the motion of the background grass will create a subset of the
pooled signals that are substantially incorrect; an MT cell analyzing the motion of the
zebra will mix together signals from the zebra&#8217;s stripes with signals from the grassy
background.
<!--l. 80--><p class="indent" >   A related problem is that computing the velocity of a pattern discards information about its
location, because receptive fields must be larger to collect pattern motion. The computation in MT
resolves pattern motion but appears to lose information about where the motion is occurring
within the large MT receptive fields (<a 
href="_masterli1.html#XMajaj:2007aa">Majaj et&#x00A0;al.</a>,&#x00A0;<a 
href="_masterli1.html#XMajaj:2007aa">2007</a>). This is puzzling because the ostensible
purpose of motion perception is often to track and anticipate the change in position of a
physical object. Consider tracking an animal moving through obscuring tall grass, or
watching waves pass over choppy water. The stalks of grass, or the foam and texture on the
water, do not progressively change position; they only oscillate in place as the movement
                                                                                         
                                                                                         
passes under them. A computation based on pattern motion would generally track the
oscillation of the surface texture rather than that of the underlying movement. However it is
the underlying movement that is more relevant, and often dominates the perception of
motion.
<!--l. 96--><p class="indent" >   Literature on visual motion processing has drawn many different demarcations between types of
motion. Various papers have discussed first-order versus second-order, short-range versus
long-range, local vs. global, textural versus figural, and so on, based on particular demarcations
drawn among stimulus properties or proposed mechanisms (<a 
href="_masterli1.html#XNishida:2011kx">Nishida</a>,&#x00A0;<a 
href="_masterli1.html#XNishida:2011kx">2011</a>). For the purposes of
this thesis I will also have to pick a demarcation. The examples of animals in the grass and waves
on the water draw a contrast between the first-order motion produced by an object, and the fact
that the object changes position over time. The latter is what I will be referring to as
position-defined motion. A moving object generally produces both first-order and position-defined
motion. To track the zebra might require integrating first-order motion signals over space and time
as the zebra changes position, while discarding adjacent signals that are inconsistent with
its trajectory. However most proposed first-order motion mechanisms do not detect
changes in position. For first-order motion processing we are reasonably confident of
the mechanisms involved, but mechanisms that detect changes in position are less well
understood.
<!--l. 115--><p class="indent" >   Note that selecting any demarcation involves some reinterpretation when reading the literature.
There is an extensive literature on second-order motion but not all of it is applicable to
position-defined motion. A typical model for second-order motion processing functions analogously
to first-order motion but with a rectifying input nonlinearity. The position-defined stimuli I will use
in this thesis might be detectable as second-order in this sense, but will be outside the temporal
frequency range thought to apply to this type of mechanism (<a 
href="_masterli1.html#XLu:2001fv">Lu and Sperling</a>,&#x00A0;<a 
href="_masterli1.html#XLu:2001fv">2001</a>). Some papers
on second-order motion stimuli use stimuli that are not position-defined, but others
use second-order stimuli that also happen to involve the movement of salient features.
                                                                                         
                                                                                         
I consider the latter results to be potentially informative of position-defined motion
processing.
<!--l. 128--><p class="indent" >   There is evidence that perception of position-defined motion stimuli may have a separate neural
substrate from first-order motion. For example, adding position-defined motion noise to a display
does not appear to change the threshold of detection for first-order motion, and it is unclear
whether adding first-order motion noise interferes with detecting position-defined motion
(<a 
href="_masterli1.html#XEdwards:1995fk">Edwards and Badcock</a>,&#x00A0;<a 
href="_masterli1.html#XEdwards:1995fk">1995</a>;&#x00A0;<a 
href="_masterli1.html#XNishida:1997aa">Nishida et&#x00A0;al.</a>,&#x00A0;<a 
href="_masterli1.html#XNishida:1997aa">1997</a>;&#x00A0;<a 
href="_masterli1.html#XCassanello:2011uq">Cassanello et&#x00A0;al.</a>,&#x00A0;<a 
href="_masterli1.html#XCassanello:2011uq">2011</a>, but see <a 
href="_masterli1.html#XHedges:2011aa">Hedges
et&#x00A0;al.</a>,&#x00A0;<a 
href="_masterli1.html#XHedges:2011aa">2011</a>). When differing first-order and position-defined components are present in a
stimulus, the motion after-effect is always determined by the first-order component,
whereas appearance of the stimulus is often determined by the position-defined motion
(<a 
href="_masterli1.html#XDerrington:1985aa">Derrington and Badcock</a>,&#x00A0;<a 
href="_masterli1.html#XDerrington:1985aa">1985</a>;&#x00A0;<a 
href="_masterli1.html#XChubb:1989fj">Chubb and Sperling</a>,&#x00A0;<a 
href="_masterli1.html#XChubb:1989fj">1989</a>;&#x00A0;<a 
href="_masterli1.html#XNishida:1992aa">Nishida and Sato</a>,&#x00A0;<a 
href="_masterli1.html#XNishida:1992aa">1992</a>).
Neuropsychological evidence suggests a double dissociation between first-order and position-defined
motion processing deficits in a number of patients (<a 
href="_masterli1.html#XVaina:1996pi">Vaina and Cowey</a>,&#x00A0;<a 
href="_masterli1.html#XVaina:1996pi">1996</a>;&#x00A0;<a 
href="_masterli1.html#XVaina:2004kx">Vaina and
Soloviev</a>,&#x00A0;<a 
href="_masterli1.html#XVaina:2004kx">2004</a>), suggesting that different motion mechanisms may have anatomically
distinct pathways. Another difference between first-order and position-defined stimuli that
suggests different mechanisms is that the latter seems to be capable of tracking objects
through over distances larger than what can be achieved through individual local filters.
&#8220;Long-range&#8221; apparent motion stimuli span a distance greater than the classical receptive field
size in V1, eliciting sensations of motion without explicit direction selective activity in
V1.
<!--l. 150--><p class="indent" >   Interestingly, the physiological substrate of position-defined motion processing is still
unclear. Cortical area MT (or somewhere downstream) has been proposed as a locus of
integration between motion and position information (<a 
href="_masterli1.html#XNishida:1999aa">Nishida and Johnston</a>,&#x00A0;<a 
href="_masterli1.html#XNishida:1999aa">1999</a>;&#x00A0;<a 
href="_masterli1.html#XMcGraw:2004aa">McGraw
et&#x00A0;al.</a>,&#x00A0;<a 
href="_masterli1.html#XMcGraw:2004aa">2004</a>;&#x00A0;<a 
href="_masterli1.html#XMather:2009aa">Mather and Pavan</a>,&#x00A0;<a 
href="_masterli1.html#XMather:2009aa">2009</a>). While the receptive fields of cells in cortical areas
MT and MST are large enough that they might be able to integrate information about
objects that change position, recordings of these cells find their responses dominated by
                                                                                         
                                                                                         
first-order motion and showing little to no selectivity to position-defined motion, even when
the latter corresponds better to the experience of viewing these stimuli (<a 
href="_masterli1.html#XLivingstone:2001ao">Livingstone
et&#x00A0;al.</a>,&#x00A0;<a 
href="_masterli1.html#XLivingstone:2001ao">2001</a>;&#x00A0;<a 
href="_masterli1.html#XIlg:2004qc">Ilg and Churan</a>,&#x00A0;<a 
href="_masterli1.html#XIlg:2004qc">2004</a>;&#x00A0;<a 
href="_masterli1.html#XHedges:2011aa">Hedges et&#x00A0;al.</a>,&#x00A0;<a 
href="_masterli1.html#XHedges:2011aa">2011</a>). So while signals present in MT have an
influence on perceived position, MT does not itself appear to track perceived position.
Despite the fact that these two motion systems clearly both contribute to determining
the appearance of the moving world, the question of whether and how they interact to
produce a single coherent percept of motion remains open (<a 
href="_masterli1.html#XNishida:2011kx">Nishida</a>,&#x00A0;<a 
href="_masterli1.html#XNishida:2011kx">2011</a>). In this thesis I
examine the combination of these two types of motion using a display that contains
first-order and position-defined components whose direction of motion can be independently
manipulated.
<!--l. 170--><p class="indent" >   <hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
<a 
 id="x2-10011"></a>
                                                                                         
                                                                                         
<!--l. 171--><p class="noindent" ><!--tex4ht:inline--><div class="tabular"> <table id="TBL-2" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-2-1g"><col 
id="TBL-2-1"><col 
id="TBL-2-2"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-2-1-"><td  style="white-space:nowrap; text-align:center;" id="TBL-2-1-1"  
class="td01">&#x00A0;<span 
class="ecbx-1728">A</span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-1-2"  
                                    class="td11">
                  <video width='640' height='272' loop=true autoplay><source src="demo_carenv.webm" type="video/webm"/><source src="demo_carenv.mov" type="video/quicktime"/> Your browser does not support the video tag. </video></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-2-"><td  style="white-space:nowrap; text-align:center;" id="TBL-2-2-1"  
class="td01">&#x00A0; <span 
class="ecbx-1728">B</span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-2-2"  
class="td11"><video width='640' height='272' loop=true autoplay><source src="demo_single.webm" type="video/webm"/><source src="demo_single.mov" type="video/quicktime"/> Your browser does not support the video tag. </video></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-3-"><td  style="white-space:nowrap; text-align:center;" id="TBL-2-3-1"  
class="td01">&#x00A0; <span 
class="ecbx-1728">C</span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-3-2"  
class="td11"><video width='640' height='272' loop=true autoplay><source src="demo_counter.webm" type="video/webm"/><source src="demo_counter.mov" type="video/quicktime"/> Your browser does not support the video tag. </video></td>
</tr><tr 
 style="vertical-align:baseline;" id="TBL-2-4-"><td  style="white-space:nowrap; text-align:center;" id="TBL-2-4-1"  
class="td01">&#x00A0;     </td></tr></table>
</div>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;1.1:  </span><span  
class="content">Examples  of  carrier/envelope  stimuli.  <span 
class="ecbx-1200">A.   </span>(<span 
class="ectt-1200">demo_carenv.mov</span>)  At  left,  an
element contains carrier (first-order) motion in the absence of higher order motion. At right,
an element whose carrier motion is balanced, but the envelope moves (higher order motion.)
<span 
class="ecbx-1200">B. </span>(<span 
class="ectt-1200">demo_single.mov</span>) Single motion elements, moving in circles. At left, the carrier motion
is opposite the envelope motion. At right, the carrier motion is in the same direction as the
envelope motion. <span 
class="ecbx-1200">C. </span>(<span 
class="ectt-1200">demo_counter.mov</span>) Five elements, each identical to the single element
in subfigure B, distributed around each fixation point. When elements are closely spaced,
there is an eccentricity-dependent change in appearance. The appearance of the wheel on
the left (with opposing carrier and envelope motions) changes depending on where the eyes
fixate.</span></div><!--tex4ht:label?: x2-10011 -->
                                                                                         
                                                                                         
<!--l. 194--><p class="indent" >   </div><hr class="endfigure">
<!--l. 197--><p class="indent" >   <a 
href="#x2-10011">Figure&#x00A0;1.1</a> provides examples of first order and higher order motion. The elements are
Gabor-like stimuli that can be understood as a carrier grating windowed by a spatial
envelope. The envelope moves independently of the carrier, so that the <span 
class="ecti-1200">carrier </span>provides
<span 
class="ecti-1200">first order motion </span>while the <span 
class="ecti-1200">envelope </span>produces <span 
class="ecti-1200">position-defined motion</span>. <a 
href="#x2-10011">Figure&#x00A0;1.1</a>A
illustrates the difference between first-order and position-defined motion. On the left is
a single element with carrier motion but no envelope motion. On the right side, the
element has envelope motion but its no carrier motion (only an equivalent amount of
flicker). The motion on the right is seen as a clear progressive change in position, while
the motion on the left has an appearance more like a flicker that has a direction to it.
(The position of the element on the left does appear to shift slightly, in an example of
motion-induced position shift; <a 
href="_masterli1.html#XDe-Valois:1991jt">De&#x00A0;Valois and De&#x00A0;Valois</a>,&#x00A0;<a 
href="_masterli1.html#XDe-Valois:1991jt">1991</a>;&#x00A0;<a 
href="_masterli1.html#XRamachandran:1990aa">Ramachandran and
Anstis</a>,&#x00A0;<a 
href="_masterli1.html#XRamachandran:1990aa">1990</a>).
<!--l. 212--><p class="indent" >   In <a 
href="#x2-10011">Figure&#x00A0;1.1</a>B, elements have both carrier and envelope motion. On the left, the carrier and
envelope components move in the same direction; on the right the carrier and envelope
motions are in opposite directions. Full details of the construction of this display are
given in <a 
href="_masterse3.html#x4-30003">Section&#x00A0;3</a>. <a 
href="#x2-10011">Figure&#x00A0;1.1</a>C is the same but with five elements around each fixation
point.
<!--l. 219--><p class="indent" >   When elements with combined envelope and carrier motions are viewed in isolation, as in
<a 
href="#x2-10011">Figure&#x00A0;1.1</a>B, the appearance of the direction of motion follows the motion of the envelope,
and not strongly affected by the direction of the carrier. The carrier motion does cause
a change in the sense of &#8220;smoothness,&#8221; with conflicting motion having a more jittery
appearance , but does not strongly affect the apparent direction or even the apparent speed of
the motion. However, in <a 
href="#x2-10011">Figure&#x00A0;1.1</a>C, when multiple elements are placed in proximity,
but not overlapping, the apparent motion depends on whether the stimulus is viewed
centrally or peripherally. When the five-element ring on the left is viewed centrally, the
                                                                                         
                                                                                         
apparent direction of motion is consistent with the envelope. When the same element
ring is viewed in the periphery, the apparent direction of rotation matches that of the
carrier. If an observer maintains attention on the leftward ring, which has carrier and
envelope in conflict, while moving their eyes so as to move the stimulus from central to
peripheral vision, the apparent motion may appear to reverse in concert with the eye
movement.
<!--l. 237--><p class="indent" >   From this demonstration it appears that having more than one element in proximity affects
how first-order and higher-order motion are combined. That the appearance changes with retinal
eccentricity of the stimulus suggests that the range of spatial interaction scales with retinal
eccentricity. A plausible explanation could be that the presence of flanking objects limits the
ability to see movement of the envelope, thereby allowing the carrier motion to determine the
percept; that is, crowding (<a 
href="_masterli1.html#XLevi:2008la">Levi</a>,&#x00A0;<a 
href="_masterli1.html#XLevi:2008la">2008</a>;&#x00A0;<a 
href="_masterli1.html#XPelli:2008nx">Pelli</a>,&#x00A0;<a 
href="_masterli1.html#XPelli:2008nx">2008</a>) may be affecting how first-order and
higher-order motion are combined.
<!--l. 247--><p class="indent" >   In this thesis I examine how first-order and higher order mechanisms interact in forming an
overall perception of motion. In <a 
href="_masterse5.html#x6-120005">Experiment 1<!--tex4ht:ref: sec:results-basic --></a> I quantify how element spacing determines the
sensitivity to first-order and higher order motions and present a simple model to capture the
results, wherein first-order and higher-order motion signals are processed separately and combined
at a decision stage. In <a 
href="_masterse6.html#x7-280006">Experiment 2<!--tex4ht:ref: sec:results-number --></a> we vary the number of elements independently of the
spacing of targets and determine that first-order motion sums inputs over a large area,
while higher order motion perception is sensitive to the spacing between elements and
flankers.
                                                                                         
                                                                                         
                                                                                         
                                                                                         
                                                                                         
                                                                                         
   <!--l. 2--><div class="crosslinks"><p class="noindent">[<a 
href="_masterse2.html" >next</a>] [<a 
href="_masterse1.html" >front</a>] [<a 
href="_master.html#_masterse1.html" >up</a>] </p></div>
<!--l. 2--><p class="indent" >   <a 
 id="tail_masterse1.html"></a>  
</body></html> 
