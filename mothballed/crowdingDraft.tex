\documentclass[11pt]{amsart}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{epstopdf}
\usepackage{hyperref}
\usepackage{jneurosci}
\usepackage[left=1.25in,right=1in,bottom=1in,top=1in,nofoot]{geometry}
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}
\title{A fixed cortical distance governs integration of local motion and position}
\author{Peter B. Meilstrup and Michael N. Shadlen}
\date{} % delete this line to display the current date
%%% BEGIN DOCUMENT
\linespread{1.6}
\begin{document}
\raggedright
\setlength{\parindent}{2em}
\maketitle
\section{Introduction}

The ability to detect moving objects is an essential function of the
visual system. Accurate motion perception is essential for visually
guided movement; complex behaviors such as chasing prey or catching a
thrown ball require that an organism be able to rapidly determine the
position and velocity of a moving object, and to anticipate its
trajectory through space.

Psychological research on motion perception has established that
separate mechanisms are involved, an idea that dates back to
Wertheimer's phenomenological distinction between fast `phi' and
slower `beta' motion \cite{Steinman:2000ap}. One mechanism responds to
the motion of visual features that are defined by luminance, or by
motion energy in the Fourier domain \cite{Adelson:1985ea}, at short
temporal and spatial scales. These stimuli contain what is variously
known as local, first-order or short range motion. Another class of
stimuli (long-range, higher-order or global motion) results in a
perception of motion without requiring features to differ in mean
luminance from the background, and without containing motion energy in
the Fourier domain. Some examples of global motion stimuli are
contrast modulation or texture flicker stimuli; the forms of global
motion are varied, but in general involve the moving modulation
(i.e. a change in position) of some visual feature over time
\cite{Lu:1995la}.

Typically, studies of visual motion have either not tried to
distinguish local from global motion, or have used stimuli intended to
drive one system without driving the other. But objects moving
realistically change position as well as possess local motion energy,
so that they activate all motion systems concurrently in varying
ways. It may be the case that there are not cleanly separated streams
of local and global motion processing, but that one form of processing
influences the other, so that the interaction between local motion and
position signals would be key to understanding global motion. Indeed
there is evidence that a system responding to a consistent change in
position of a stimulus interacts with the output of local motion
detectors. In a field of dots undergoing random Brownian movement, a
single dot that changes its position in a consistent direction is more
easily detected than local motion energy detectors can account for
\cite{Verghese:1999lq}. The enhancement in detectability seems to
occur only after 100 ms of movement, possibly due to a process that
responds to an initial cue from local motion detectors by reducing the
number of detectors monitored to those in the vicinity of the initial
motion signal, in particular those in the object's predicted path
\cite{VerghesePreeti2002}. An interaction between local motion and
position sensors thus appears necessary to account for performance at
motion discrimination.

To investigate the interaction between local motion and position
signals, we constructed stimuli that combined a local motion with
global position shift. By setting the local motion and position shift
in opposition, we produced a striking illusion. Here (Movie 1) we show
a display with two wheels, each containing five spots. The spots are
composed of Cauchy wavelets designed to drive local motion sensors,
with no change in mean luminance of feature against background
\cite{Klein:1985rz}. Independent of its local motion, each spot is
given a global apparent motion, by presenting it at successive
locations at intervals of 100 ms. On the left side of the display, the
local motion and position change are in the same direction; on the
right side the local motion and position change are in opposite
directions. Full details of the construction of this display are given
in Methods.

[MOVIE 1]

In this display the rotation of the spots around the fixation point on
the left side of the display appears constant regardless of viewing
angle, but the motion of the spots in the right side appears to change
direction based on retinal eccentricity. When fixating in the center
of the right circle, the spots appear to travel clockwise around the
circle; when viewed parafoveally, the spots appear to move
counterclockwise. When making an eye movement that shifts the right
circle from a parafoveal to a foveal location, or vice versa, it
appears to suddenly reverse its direction.

An eccentricity-dependent reversal in perceived direction has been
previously reported for some reverse-phi stimuli
\cite{Mather:1985rt,Chubb:1989fj}; a display similar to ours,
arranging discrete elements in circles, has also been independently
developed by \citetext{Shapiro:2008ek}. \citetext{Chubb:1989fj}
proposed that the global motion in reverse-phi displays was detected
by rectification of the output of some feature detectors, after which
a more normal motion-energy filtering process followed, and that the
resolution of this rectification and detection was weaker in the
periphery. Because our display assigns local and global motion to the
same features, it was natural to ask whether the eccentricity-driven
reversal of apparent motion direction happened with only one spot
moving around the fixation point. It did not; when all but one of the
spots in the circle were eliminated, the remaining spot appeared to
move consistent with its global position shift, regardless of
eccentricity. Because the targets were the same size in both conditions, a motion energy
detector operating on rectified input should have performed as well in both
cases. Instead this illusion suggested that a long range interference
between the distinct elements was responsible for the failure of
global apparent motion in parafoveal viewing. In other words, a form
of crowding limits the detection of shifts in global position.

Crowding is a phenomenon wherein identification or discrimination of
an object presented in the visual periphery is impaired by the
presence of nearby, but non-overlapping flanking objects. A finding
characteristic of crowding is that critical spacing (usually a measure
of the distance between target and flanker which achieves a particular
elevation of threshold for recognition) scales linearly with retinal
eccentricity \cite{Bouma:1970ng,Toet:1992db}. Although most studies of
crowding focus on its effect of impairing the recognition of shapes
(e.g. letters) in parafoveal vision, it has become apparent that
crowding is a more general phenomenon, extending to many different
types of visual features (e.g. \citenoparens{Berg:2007rc}; for review,
see \citenoparens{Levi:2008la}) It is thought that crowding is
characteristic of some cortical mechanism that integrates signals from
low-level feature detectors, a so-called ``integration field''
\cite{Pelli:2004km}. Because the scaling of critical distance with
spacing mirrors the variation of cortical magnification with
eccentricity, the integration field is thought to be a process that
subsumes a constant distance on the cortical surface
\cite{Pelli:2008nx}.

\citetext{Pelli:2004km} proposed that the crucial diagnostic test for
crowding as opposed to masking or other forms of spatial interference
is that the critical spacing scales with eccentricity and is
relatively unaffected by signal size. Accordingly, we set out to
determine which target spacing and motion parameters are necessary to
drive the reversal of apparent motion as various eccentricities. In
Experiment 1 below, we determine the relationship between critical
spacing and target spacing, which satisfies Bouma's law. In Experiment
2 we show that the critical distance and scaling property is robust to
the size of the stimuli. We also test its robustness to variations
in temporal frequency, step size, and step interval. In Experiment 3
we show that the critical spacing is unaffected by the presence of an
occluder which covers 2/3 of the visible circle, meaning that it is
the spacing which is relevant and not the number of visible targets.

While most studies of crowding involve stationary stimuli, motion
stimuli add a temporal component. In Experiments 1 through 3 we
consistently find that for stimuli near the crowding distance, the
trials for which the subject took longer in responding were more
likely to correctly reflect the global direction of motion. In
Experiment 4 we use an auditory cue to vary the subjects' response
time to investigate this effect in more detail. Our results reinforce
the idea that global motion processing is the result of an integration
of the output of low-level feature detectors, and that in fact the
process subserving detection of global motion might be identical to
the processes underlying object recognition and target selection. We
discuss the implications for possible mechanisms of higher order
motion perception and speculate on their possible physiological
implementations.

\section{Methods}

\subsection{Subjects}

Five subjects took part in this series of experiments. The subjects
and the experiments they took part in are listed in Table 1. Subject
P.M. is an author. Subject S.K. was made aware of the purpose of the
experiments only after completing Experiment 1. Subjects S.M., D.T.,
and G.B. were paid and were naive to the purpose of the experiments.

\subsection{Equipment}

Stimuli were presented on a flat CRT video monitor (ViewSonic PF790;
$800 \times 600$ pixels; display area $341 \times 256$ mm; 120Hz
refresh rate) Experiments were programmed in MATLAB using the
Psychtoolbox \cite{Brainard:1997gq} and Eyelink toolbox extensions
\cite{Cornelissen:2002wl}, along with custom OpenGL code. All stimuli
were presented on a 50\% gray background whose luminance was $33.10
cd/m^2$. The display had a black level of $0.10 cd/m^2$ and a white of
$66.05 cd/m^2$ measured against the gray background.

Subjects sat behind a blackout curtain so that ambient illumination
was mostly due to the monitor and viewed the screen binocularly using
a chin and forehead rest with the eyes 60 cm from the screen. Eye
position was monitored using a video-based eye tracker (EyeLink 1000;
SR Research) using a sample rate of 250 Hz. Eye movements were
recorded but are not reported in this paper. Subjects gave responses
by turning a knob (PowerMate; Griffin Technologies) with their
preferred hand.

\subsection{Stimuli}

The visual stimuli consisted of discrete local motion elements
presented at regular temporal and spatial intervals as in apparent
motion. Each local motion element had a luminance profile along the
direction of motion given by a Cauchy filter function
\cite{Klein:1985rz} with peak spatial frequency $f$. The luminance
profile shifts phase with a constant temporal frequency $\omega$ and
is temporally modulated by a Gaussian envelope with standard deviation
$d/2$. At right angles to the direction of motion each local motion
element had a Gaussian envelope with standard deviation $w/2$. The
equation describing the luminance profile of a patch as a function of
position and time is then:
\begin{equation}
C(x, y, t) = \mathrm{cos}^n(\mathrm{tan}^{-1}(fx/n))\mathrm{cos}(n \cdot \mathrm{tan}^{-1}(fx/n) + {\omega}t) e^{-(t/2d)^2-(y/2d)^2}
\end{equation}
with the direction of motion along $x$. The spatial frequency tuning
parameter $n$ was set to 4 for all stimuli.

\begin{table}
\begin{tabular}{r | l l}
Subject & Experiments & Response window \\
\hline
P.M. & Exp. 1, Exp. 2 (${\Delta}x$, $f$, $\omega$), Exp. 3, Exp. 4 & 400-750 ms \\
S.K. & Exp. 1 & 400-750 ms \\
S.M. & Exp. 1 & 400-750 ms \\
D.T. & Exp. 1, Exp. 2 (${\Delta}x$, $f$, $\omega$), Exp. 3 & 500-850 ms \\
G.B. & Exp. 1*, Exp. 2* (${\Delta}x$*, $\omega$*), Exp. 3*, Exp. 4* & 300-650 ms \\
\hline
\end{tabular}
\caption{Overview of the experiments and participants. In sessions marked with
  * G.B. used a spatial frequency of 8.8 cyc/${\phi}$; other subjects used a spatial frequency of 13.03 cyc/${\phi}$.}
\end{table}

In each trial, a number of identical elements were arranged in a
circle around the fixation point, each oriented with the direction of
motion tangential to the circle. Each element was presented repeatedly
at intervals of ${\Delta}t$, each successive appearance displaced a
fixed distance ${\Delta}x$ around the circle. The examples in Movie 2
have the following settings, the same as used for subject G.B. in
Experiment 1: ${\Delta}t = 100$ ms, $\omega = 10$ cyc/s, $d$ = 0.033 s, and
if $\phi$ denotes eccentricity, then $f = 8.9 cyc/\phi$,
${\Delta}x = 0.05 \cdot \phi$, and $w = 0.066 \cdot \phi$. The peak
contrast of the local motion elements was always $70.7\%$.

[Movie 2]

\subsection{Task}

The task is illustrated in Figure 1a. Each trial began with the
appearance of a central fixation point, 0.2 degrees in diameter. After
the subject fixated, there was a variable delay of 350-1350 ms, drawn
from a truncated exponential distribution ($\tau = 1$ s), before the
onset of a motion stimulus. Any fixation breaks or blinks between the
start of fixation and motion offset caused the trial to abort and be
reshuffled to be repeated later. At the end of each trial subjects
indicated the perceived direction of rotation of the stimulus by
turning a knob through an angle of at least 12 degrees either
clockwise or counterclockwise. Subjects were aware of the distinction
between local motion and global translation and were instructed to
respond according to what they perceived to be the direction of global
motion. There was a delay of at least 500 ms between the subject's
response and the beginning of the next trial.

For Experiments 1, 2, and 3, subjects were required to respond within
a fixed temporal window. If the latency from motion onset to response
was outside the window, the fixation point changed color (red for late
responses, blue for early responses) for 1 second as feedback and the
trial was reshuffled into the stimulus set to be repeated later in the
session. The response window was chosen for each subject based on
preliminary sessions and is listed in Table 1.

Subjects performed the task in sessions of at most 1 hour, divided
into 4 or 5 blocks of 150 to 200 trials each, and were prompted to
take a break between blocks. Subjects could also rest at any point by
simply delaying fixation. At the beginning of each block, the eye
tracking system was recalibrated by asking the subject to make
saccades to a number of targets at randomly chosen locations on the
screen.

For all experiments reported here, three stimulus types were used with
equal probability. In one third of trials the direction of local
motion was congruent with that of global motion. In the second third,
the direction of local motion was opposite to the direction of global
motion. In the remaining trials, elements with ambivalent local motion
direction were used. Ambivalent elements were constructed by
superposing two local motion elements with equal and opposite
directions of local motion, each reduced to 50\% contrast; i.e. the
ambivalent elements have the same spatial and temporal frequency
content as the congruent and incongruent elements, but their motion
energy is equivocal between opposite directions. The third stimulus in
Movie 2 shows ambivalent local motion.

During the first training session we omitted the incongruent motion
stimulus and substituted a stimulus with local motion only
(i.e. ${\Delta}x = 0$,) so that there was no ambiguity about the
correct response during training. Subjects were required to answer
better than 90\% correct in all conditions at all eccentricities
during the training task before proceeding with other
experiments. During training sessions we found that subject G.B. was
unable to reliably discriminate local motion direction when the
spatial frequency was more than $10 cyc/\phi$. He was excluded from
the spatial frequency control in Experiment 2 and other experiments
with that subject used the lower spatial frequency value of $8.8
cyc/\phi$.
 
\section{Results}

\subsection{Experiment 1}

We presented stimuli at eccentricities of 10, 6.67, 4.44, and 2.96
degree, using the parameters described above for Supplementary Movie 1
but scaling all spatial parameters (${\Delta}x$, $w$, $1/f$) of the
elements along with the eccentricity; i.e. at eccentricity of 6.67
degree, ${\Delta}x$ and $w$ decreased to 2/3 the value used at 10
degrees and $f$ increased to 3/2 its value. The global apparent motion
was shown over 4 stations at intervals of ${\Delta}t=100$ ms.

We varied the number of (and consequently the inter-target
spacing) in the circle using the method of constant stimulus, using
values chosen for each subject based on preliminary sessions.  Using
the third of trials where global motion opposed local, we obtained a
psychometric function relating the target spacing to the probability
that the stimulus is seen to rotate in the direction of the global
motion. The data were fit to a cumulative logistic function using a
maximum likelihood estimator. We used the 50\% threshold as an estimate of the
critical spacing at which the local motion signal interferes with the
global motion signal.

\begin{figure}
  \caption{Perceived motion direction is determined by a critical target spacing
    which scales with stimulus eccentricity. A. Task structure:
    Subjects view a display with local, global and
    ambiguous stimuli. B. Example psychometric functions for subject D.T. Proportion
    of response agreeing with global motion in trials where local motion opposed
    global is plotted against target spacing for four test
    eccentricities along with psychometric function fits. C. Measured
    points of subjective equivalence for target spacing versus target eccentricity for all
    five subjects. Bars indicate confidence intervals. Lines show the
    fit of a logistic GLM to each subject's data. }
\end{figure}

\subsection{Experiment 2}

A noted property of crowding in parafoveal vision is that the range of
spatial interaction between nearby targets is not dependent on the
size of the stimuli \cite{Levi:2002cs}. To determine whither the
motion reversal illusion shared this property we collected thresholds
for each eccentricity under altered stimulus configurations. In
separate sessions we varied spatial frequency (using values of $\phi$
scaled by 66\%, 100\% and 150\% compared to Experiment 1), temporal
frequency (using values of 6.6, 10, and 15 Hz), spatial step size
(scaling values of ${\Delta}x$ by 66\%, 100\% and 150\% compared to
Experiment 1), and temporal step interval (using ${\Delta}t$ values of
66, 100, and 150 ms, and $d$ values of 44, 66, and 100 ms,
respectively). For these experiments we used the QUEST procedure
\cite{Watson:1983hc} to select the the number of targets at each
trial. As before, there were three types of trials, with local motion
congruent, incongruent, or ambivalent to the global translation. The
QUEST algorithm selected the target spacing for all trial types, but
the subject's response was used to update the QUEST estimate only for
trials with local motion incongruent to global. Separare, randomly
interleaved estimations were performed for each stimulus configuration
and eccentricity. The QUEST algorithm was only used to efficiently
select stimulus values and not to obtain final threshold estimates; we
re-fit the data using maximum likelihood logistic regression, as in
Experiment 1.

\begin{figure}
  \caption{Effect of target properties on critical spacing. A. Each
    plot shows critical spacing versus eccentricity for three
    different stimulus conditions. in one subject. B. Normalized
    logistic regression coefficient for each stimulus condition in
    each subject. * indicates significance ($p < 0.5$) }
\end{figure}

\subsection{Experiment 3}

In the above experiments the critical spacing between targets appears
to scale linearly with eccentricity, and to be relatively insensitive
to the other parameters. This results in the stimulus at threshold
having roughly the same number of elements for each configuration. An
alternative explanation for the results might be that monitoring the
displacement of multiple targets employs a limited attentional
resource which is overwhelmed when the some critical number of
targets is exceeded. To distinguish these possibilities we covered all
but $120^\circ$ of the motion stimulus with a C-shaped occluder,
covering the circles in which the targets traveled and leaving an arc
of 120 degrees visible on either the left or right side. The occluder
had a contrast of 2.5\%. For each subject we found the critical
spacing for left and right sides of the display in separate sessions;
in both sessions 1/3 of trials had no occluder so that we could
compare performance with and without occluders within a session.
Again we used the QUEST procedure to choose the target spacing for
each trial.

\begin{figure}
  \caption{Critical spacing is unaffected by removing most
    elements. A. Example stimulus: motion targets are hidden by an
    occluder with a $120^\circ$ window on the left or right
    side. B. Critical spacing as a function of eccentricity in visible
    left,visible right, and unoccluded conditions.}
\end{figure}

\subsection{Experiment 4: Temporal evolution of motion reversal}

%Temporal properties of integration
Near the 50\% threshold, subjects often reported seeing a direction of
motion consistent with the local motion at first, but that the
perceived motion then shifted towards that of global. Correspondingly
we find that in trials where the responses were delayed relative to
motion onset, the responses were more likely to agree with the global
direction. Global motion requires the appearance of the target in
distinct positions, so the global motion signal is only present after
two stations of the apparent motion have elapsed. Therefore the
integration of the local signal with global must take place over
time. To investigate the temporal properties of this integration, we
used an audio cue to dictate the subject's response time. A series of
three clicks, at 500 ms intervals was played during each trial;
subjects had to give their response within 100 ms, in either
direction, of the third click. The onset time of the clicks was varied
relative to the motion onset from trial to trial.

\begin{figure}
  \caption{Temporal evolution of motion reveral. A. Data from figure
    1B are replotted by individual trials, showing the effect of
    response time. Filled symbols indicate response according to
    global direction, open symbols indicate response according to
    local direction. Horizontal dotted lines indicate the early and
    late response deadlines for this subject. B. Responses with
    varying, cued response readlines for one stimulus
    condition. C. 50\% threshold and slope of the psychometric
    function for }
\end{figure}

\section{Discussion}

[This is by no means complete or organized, just starting to lay out a
couple of points I want to explore.]

Having two classes of stimuli that are well distinguished
behaviorally, we would hope to be able to find neurophysiological
correlates of both types of motion perception. The underpinnings of
local motion are \citetext{Vaina:1996pi} provides one positive
finding, a patient with a unilateral cortical lesion slightly
posterior to the hMT+ complex, resulting in a deficit in detection of
global but not local motion in the contralateral field. Because
receptive fields in MT are large, reflecting the integration of many
V1 receptive fields spanning a range of spatial positions, it is
natural to suppose that a global motion process could be supported by
MT. However, attempts to observe MT neurons in the act of responding
to global, as opposed to local, motion, have met with little
success. For example, when random dot local motion stimuli are
presented in a window that moves independently of the dots, MT cells
respond primarily to to the local
motion \cite{Priebe:2001hl}. Responses in macaque MT and MST to a
stimulus opposing local and global motion showed no selectivity of
cell responses to global motion direction, even though the stimuli
elicited an oculomotor pursuit response in the direction of global
motion \cite{Ilg:2004qc}. \citetext{Livingstone:2001ao} used sparse
noise to map second-order spatiotemporal kernels in MT receptive
fields and could not find any spatiotemporal interaction at scales
larger than those of V1 receptive fields. Finally, recordings in MT
made using stimuli similar to those used in this report find no
selectivity in MT cells for global
motion \cite{Shadlen:1993ne,Hedges:2004pr}. It appears that direction
selective responses in MT are, like those of V1, a function of local,
and not global, motion.

As mentioned in the introduction, \citetext{VerghesePreeti2002} found
that detectability of a single dot with consistent direction among
randomly moving backgrounds was enhanced after 100 ms of target
motion. In that report they also show (Figure 1 of that paper) that
there is some enhancement is preserved even if the target motion is
discontinuous; a target that suddenly jumped sideways or backwards in
the middle of its motion trajectory still had enhanced detectability
relative to the baseline. However, if the size of the jump was too
large, the enhancement vanished vanished. In the light of the present
study, we suggest that the critical maximum jump size may be the same
as the critical spacing of crowding. The enhancement observed in that
paper has been interpreted as a process that responds to an initial
cue from local motion detectors by reducing the number of detectors
monitored to just those in the vicinity of the initial motion
signal. It may be that the mechanism that winnows the pool of motion
detectors is the same as the integration field of \cite{Pelli:2004km}.

\bibliographystyle{jneurosci}
\bibliography{bibliography}

\end{document}  